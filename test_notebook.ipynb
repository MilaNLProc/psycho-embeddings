{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5c830698-b497-4b30-8339-91d031106c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from psycho_embeddings.fresh_embedder import ContextualizedEmbedder\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import pickle\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3aa519-f5d0-4cdb-b53b-b185c94b460d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ContextualizedEmbedder(\"bert-base-cased\", 300, device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "16a2091a-9285-410d-9b6a-f22e57beadb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_index_for_word(word, data):\n",
    "    \"\"\"\n",
    "    Given a word and a dataframe, finds the idxs of that word in the dataframe\n",
    "    \"\"\"\n",
    "    return data[data[\"words\"] == word].index.tolist()\n",
    "\n",
    "def get_average_word_embeddings(word, data, embeds):\n",
    "    \"\"\"\n",
    "    Given a word, a data, and the embeddings, it averages the embeddings of that word\n",
    "    \"\"\"\n",
    "    idxs = find_index_for_word(word, data)\n",
    "    if len(idxs) > 1:\n",
    "        return np.average(itemgetter(*idxs)(embeds), axis=0)\n",
    "    else:\n",
    "        return np.array(embeds[idxs[0]]) # idxs is a list of lists so we access the first element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "96c1faed-1e3f-4976-99de-9754c89bdc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({\"words\" : [\"cat\", \"dog\", \"cat\"], \"target_text\" : [\"the cat is on the table\", \"the dog is on the table\", \"the cat is on the table\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "800389cb-7bd2-4759-94bc-fbd55f4b1448",
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE_CHUNKS = 2  #chunk row size\n",
    "FOLDER_NAME = \"bert_embeddings\"\n",
    "GPU = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e096acae-ccdb-441f-af11-7f87401e3901",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_of_interest = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
    "list_df = [data[i:i+SIZE_CHUNKS] for i in range(0,data.shape[0],SIZE_CHUNKS)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f8eec2-a5a4-447b-99cc-b99563f5b8b0",
   "metadata": {},
   "source": [
    "# Create Embeddings for The Enitre Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9fb4bf99-fdec-41e9-bcea-1b7df1f28799",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:26<00:00, 13.16s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "331666900bfb4bbabb0dfe7140c77495",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.56it/s]\n",
      " 50%|█████     | 1/2 [00:01<00:01,  1.20s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a96f2eadb7846fca6644fdac8457e39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.85it/s]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.04it/s]"
     ]
    }
   ],
   "source": [
    "pbar = tqdm(total=len(list_df), position=0)\n",
    "\n",
    "for index, sub_portion_od_data in enumerate(list_df):\n",
    "\n",
    "    #############################\n",
    "    # DUMPING EMBEDDING ON DISK #\n",
    "    #############################\n",
    "\n",
    "    df_slice_embedded = embeddings = model.embed(sub_portion_od_data[\"target_text\"].tolist(), sub_portion_od_data[\"words\"].tolist(), layers_of_interest, 8, averaging=True)\n",
    "\n",
    "    for layer in layers_of_interest:\n",
    "        os.makedirs(f\"{FOLDER_NAME}/{layer}/temp/\", exist_ok=True)\n",
    "\n",
    "        with open(f\"{FOLDER_NAME}/{layer}/temp/bert_embeddings_{index}\", \"wb\") as filino:\n",
    "            pickle.dump((df_slice_embedded[layer]), filino)\n",
    "\n",
    "    if index%10==0:\n",
    "        gc.collect()\n",
    "    pbar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7240410-019d-48e9-ba12-d0c51ed98dd2",
   "metadata": {},
   "source": [
    "# Reconstruct and Save Contextualzied Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6c0df410-dd4b-4d33-a86d-c1a2368b25c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 2658.83it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 3622.02it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 4851.71it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 5200.62it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 5429.52it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 10908.46it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 1390.68it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 2286.97it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 2004.93it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 3960.63it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 3309.12it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 4422.04it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 4044.65it/s]\n",
      "Layer: 100%|██████████| 13/13 [00:00<00:00, 209.49it/s]\n"
     ]
    }
   ],
   "source": [
    "for LAYER in tqdm(range(13), desc=\"Layer\"):\n",
    "    # We load all the embeddings from disk, in order and reconstruct the actual embedding for a specific layer for the entire dataframe.\n",
    "    \n",
    "    emb_files = sorted(glob(f\"{FOLDER_NAME}/{LAYER}/temp/*\"), key=lambda x: int(os.path.basename(x).split(\"_\")[-1]))\n",
    "    assert len(emb_files) == len(list_df) # sanity check\n",
    "    \n",
    "    all_the_embeddings = []\n",
    "    pbar = tqdm(total=len(list_df), position=0)\n",
    "    \n",
    "    for ff in emb_files:\n",
    "        with open(ff, \"rb\") as filino:\n",
    "            ldata = pickle.load(filino)\n",
    "            pbar.update(1)\n",
    "            for value in ldata:\n",
    "                if len(value) == 1:\n",
    "                    all_the_embeddings.append(np.array(value[0]))\n",
    "                else:\n",
    "                    all_the_embeddings.append(np.array(value))\n",
    "    pbar.close()\n",
    "    \n",
    "    all_the_embeddings = np.array(all_the_embeddings)\n",
    "    \n",
    "\n",
    "    with open(f'{FOLDER_NAME}/contextualized_embeddings_bert_{LAYER}_layer.npy', 'wb') as f:\n",
    "        np.save(f, all_the_embeddings)\n",
    "\n",
    "    del all_the_embeddings\n",
    "\n",
    "    embeds = np.load(f\"{FOLDER_NAME}/contextualized_embeddings_bert_{LAYER}_layer.npy\")\n",
    "\n",
    "    ##################\n",
    "    # MAP 2 Sentence #\n",
    "    ##################\n",
    "        \n",
    "    # NOTE:    \n",
    "    # NOTE: This is probably dataset specific? but also, do we really need this? seems to be only the index dumped on disk?\n",
    "    # NOTE:\n",
    "    \n",
    "    map_sentrepl2emb = {\n",
    "        (row[\"words\"], row[\"target_text\"]): idx for idx, row in data.iterrows()\n",
    "    }\n",
    "\n",
    "    with open(f\"{FOLDER_NAME}/map_sentrepl2embbert_{LAYER}.pkl\", \"wb\") as file_to_save:\n",
    "        pickle.dump(map_sentrepl2emb, file_to_save)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ba6aac96-f857-4b63-bbef-10175113766f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 1273.51it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 1597.22it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 2016.01it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 1544.58it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 2060.07it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 665.82it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 986.66it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 1280.51it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 1053.05it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 816.33it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 566.64it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 925.79it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 972.48it/s]\n",
      "Layer: 100%|██████████| 13/13 [00:00<00:00, 135.84it/s]\n"
     ]
    }
   ],
   "source": [
    "for LAYER in tqdm(range(13), desc=\"Layer\"):\n",
    "    emb_files = sorted(glob(f\"{FOLDER_NAME}/{LAYER}/temp/*\"), key=lambda x: int(os.path.basename(x).split(\"_\")[-1]))\n",
    "    assert len(emb_files) == len(list_df) # sanity check\n",
    "\n",
    "    ##############################\n",
    "    # Build Prototype Embeddings #\n",
    "    ##############################\n",
    "    \n",
    "    embeds = np.load(f\"{FOLDER_NAME}/contextualized_embeddings_bert_{LAYER}_layer.npy\")\n",
    "\n",
    "    mega_embeddings = {}\n",
    "    pbar = tqdm(total=len(data[\"words\"].unique()), position=0)\n",
    "    for word in data[\"words\"].unique():\n",
    "        emb = get_average_word_embeddings(word, data, embeds)\n",
    "        mega_embeddings[word] = emb \n",
    "        pbar.update(1)\n",
    "    pbar.close()\n",
    "\n",
    "    with open(f\"{FOLDER_NAME}/prototype_embeddings_bert_{LAYER}.pkl\", \"wb\") as filino:\n",
    "        pickle.dump(mega_embeddings, filino)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3464271-5923-4584-85eb-e51321ca85d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newkernel",
   "language": "python",
   "name": "newkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

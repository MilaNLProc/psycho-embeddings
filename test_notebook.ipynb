{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34b17af5-816c-4f29-90c7-7e2aa3b9a90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c830698-b497-4b30-8339-91d031106c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vinid/PycharmProjects/psycho_embeddings/env/lib/python3.10/site-packages/torch/cuda/__init__.py:88: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from psycho_embeddings.fresh_embedder import ContextualizedEmbedder\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import pickle\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "from operator import itemgetter\n",
    "from numpy import zeros, dtype, float32 as REAL, ascontiguousarray, fromstring\n",
    "from gensim import utils\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee3aa519-f5d0-4cdb-b53b-b185c94b460d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /home/vinid/.cache/huggingface/hub/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_hidden_states\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /home/vinid/.cache/huggingface/hub/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/pytorch_model.bin\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertModel were initialized from the model checkpoint at bert-base-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n",
      "loading configuration file config.json from cache at /home/vinid/.cache/huggingface/hub/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading file vocab.txt from cache at /home/vinid/.cache/huggingface/hub/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/vocab.txt\n",
      "loading file tokenizer.json from cache at /home/vinid/.cache/huggingface/hub/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at /home/vinid/.cache/huggingface/hub/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/tokenizer_config.json\n",
      "loading configuration file config.json from cache at /home/vinid/.cache/huggingface/hub/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = ContextualizedEmbedder(\"bert-base-cased\", max_length=300, device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "16a2091a-9285-410d-9b6a-f22e57beadb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_index_for_word(word, data):\n",
    "    \"\"\"\n",
    "    Given a word and a dataframe, finds the idxs of that word in the dataframe\n",
    "    \"\"\"\n",
    "    return data[data[\"words\"] == word].index.tolist()\n",
    "\n",
    "def get_average_word_embeddings(word, data, embeds):\n",
    "    \"\"\"\n",
    "    Given a word, a data, and the embeddings, it averages the embeddings of that word\n",
    "    \"\"\"\n",
    "    idxs = find_index_for_word(word, data)\n",
    "    if len(idxs) > 1:\n",
    "        return np.average(itemgetter(*idxs)(embeds), axis=0)\n",
    "    else:\n",
    "        return np.array(embeds[idxs[0]]) # idxs is a list of lists so we access the first element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "96c1faed-1e3f-4976-99de-9754c89bdc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({\"words\" : [\"cat\", \"dog\", \"cat\"], \"target_text\" : [\"the cat is on the table\", \"the dog is on the table\", \"the cat is on the table\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "800389cb-7bd2-4759-94bc-fbd55f4b1448",
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE_CHUNKS = 2  #chunk row size\n",
    "FOLDER_NAME = \"bert_embeddings\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e096acae-ccdb-441f-af11-7f87401e3901",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_of_interest = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
    "list_df = [data[i:i+SIZE_CHUNKS] for i in range(0,data.shape[0],SIZE_CHUNKS)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f8eec2-a5a4-447b-99cc-b99563f5b8b0",
   "metadata": {},
   "source": [
    "# Create Embeddings for The Enitre Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9fb4bf99-fdec-41e9-bcea-1b7df1f28799",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                       | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e114774403194cf0b1ccbbc3f4fd7968",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text tokenization:   0%|          | 0/2 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 1/1 [00:00<00:00,  1.41it/s]\n",
      " 50%|███████████████████████▌                       | 1/2 [00:01<00:01,  1.52s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c59663e8eb444ec95c1b28622775b1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text tokenization:   0%|          | 0/1 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 1/1 [00:00<00:00,  2.60it/s]\n",
      "100%|███████████████████████████████████████████████| 2/2 [00:02<00:00,  1.18s/it]"
     ]
    }
   ],
   "source": [
    "pbar = tqdm(total=len(list_df), position=0)\n",
    "\n",
    "for index, sub_portion_od_data in enumerate(list_df):\n",
    "\n",
    "    #############################\n",
    "    # DUMPING EMBEDDING ON DISK #\n",
    "    #############################\n",
    "\n",
    "    df_slice_embedded = embeddings = model.embed(\n",
    "        words=sub_portion_od_data[\"words\"].tolist(),\n",
    "        layers_id=layers_of_interest,\n",
    "        target_texts=sub_portion_od_data[\"target_text\"].tolist(),\n",
    "        batch_size=8,\n",
    "        averaging=True,\n",
    "        return_static=True,\n",
    "        show_progress=True\n",
    "    )\n",
    "\n",
    "    for layer in [-1] + layers_of_interest:\n",
    "        os.makedirs(f\"{FOLDER_NAME}/{layer}/temp/\", exist_ok=True)\n",
    "\n",
    "        with open(f\"{FOLDER_NAME}/{layer}/temp/bert_embeddings_{index}\", \"wb\") as filino:\n",
    "            pickle.dump((df_slice_embedded[layer]), filino)\n",
    "\n",
    "    if index%10==0:\n",
    "        gc.collect()\n",
    "    pbar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7240410-019d-48e9-ba12-d0c51ed98dd2",
   "metadata": {},
   "source": [
    "# Reconstruct and Save Contextualzied Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6c0df410-dd4b-4d33-a86d-c1a2368b25c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████████| 2/2 [00:02<00:00,  1.24s/it]\u001B[A\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00, 1636.16it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00, 5949.37it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00, 6100.81it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00, 5226.55it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00, 5979.05it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00, 4996.19it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00, 4657.75it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00, 5793.24it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00, 6168.09it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00, 7002.18it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00, 5136.93it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00, 6775.94it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00, 5226.55it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00, 5664.15it/s]\n",
      "Layer: 100%|█████████████████████████████████████| 14/14 [00:00<00:00, 336.25it/s]\n"
     ]
    }
   ],
   "source": [
    "for LAYER in tqdm(range(-1, 13), desc=\"Layer\"):\n",
    "    # We load all the embeddings from disk, in order and reconstruct the actual embedding for a specific layer for the entire dataframe.\n",
    "\n",
    "    emb_files = sorted(glob(f\"{FOLDER_NAME}/{LAYER}/temp/*\"), key=lambda x: int(os.path.basename(x).split(\"_\")[-1]))\n",
    "    assert len(emb_files) == len(list_df) # sanity check\n",
    "\n",
    "    all_the_embeddings = []\n",
    "    pbar = tqdm(total=len(list_df), position=0)\n",
    "\n",
    "    for ff in emb_files:\n",
    "        with open(ff, \"rb\") as filino:\n",
    "            ldata = pickle.load(filino)\n",
    "            pbar.update(1)\n",
    "            for value in ldata:\n",
    "                if len(value) == 1:\n",
    "                    all_the_embeddings.append(np.array(value[0]))\n",
    "                else:\n",
    "                    all_the_embeddings.append(np.array(value))\n",
    "    pbar.close()\n",
    "\n",
    "    all_the_embeddings = np.array(all_the_embeddings)\n",
    "\n",
    "\n",
    "    with open(f'{FOLDER_NAME}/contextualized_embeddings_bert_{LAYER}_layer.npy', 'wb') as f:\n",
    "        np.save(f, all_the_embeddings)\n",
    "\n",
    "    del all_the_embeddings\n",
    "\n",
    "    ##################\n",
    "    # MAP 2 Sentence #\n",
    "    ##################\n",
    "\n",
    "    # NOTE:\n",
    "    # NOTE: This is probably dataset specific? but also, do we really need this? seems to be only the index dumped on disk?\n",
    "    # NOTE:\n",
    "\n",
    "    map_sentrepl2emb = {\n",
    "        (row[\"words\"], row[\"words\"], row[\"target_text\"], idx): idx for idx, row in data.iterrows()\n",
    "    }\n",
    "\n",
    "    with open(f\"{FOLDER_NAME}/map_sentrepl2embbert_{LAYER}.pkl\", \"wb\") as file_to_save:\n",
    "        pickle.dump(map_sentrepl2emb, file_to_save)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11549096-9eb8-4ddd-8151-03d695232561",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e08a68c-2ff1-4c7f-afa1-dd0ae764d9f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7b8496df-0691-4ab5-8aec-fe0424e5df7f",
   "metadata": {},
   "source": [
    "### Prototype Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ba6aac96-f857-4b63-bbef-10175113766f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████| 2/2 [00:00<00:00, 412.87it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00, 2077.93it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00, 2470.87it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00, 1503.87it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00, 2465.06it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00, 2109.28it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00, 1882.54it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00, 2607.59it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00, 1652.93it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00, 1065.36it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00, 1188.69it/s]\n",
      "100%|██████████████████████████████████████████████| 2/2 [00:00<00:00, 812.14it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00, 1409.61it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00, 1540.61it/s]\n",
      "Layer: 100%|█████████████████████████████████████| 14/14 [00:00<00:00, 144.46it/s]\n"
     ]
    }
   ],
   "source": [
    "for LAYER in tqdm(range(-1, 13), desc=\"Layer\"):\n",
    "    #emb_files = sorted(glob(f\"{FOLDER_NAME}/{LAYER}/temp/*\"), key=lambda x: int(os.path.basename(x).split(\"_\")[-1]))\n",
    "    #assert len(emb_files) == len(list_df) # sanity check\n",
    "\n",
    "    ##############################\n",
    "    # Build Prototype Embeddings #\n",
    "    ##############################\n",
    "\n",
    "    embeds = np.load(f\"{FOLDER_NAME}/contextualized_embeddings_bert_{LAYER}_layer.npy\")\n",
    "\n",
    "    mega_embeddings = {}\n",
    "    pbar = tqdm(total=len(data[\"words\"].unique()), position=0)\n",
    "    for word in data[\"words\"].unique():\n",
    "        emb = get_average_word_embeddings(word, data, embeds)\n",
    "        mega_embeddings[word] = emb\n",
    "        pbar.update(1)\n",
    "    pbar.close()\n",
    "    \n",
    "    \n",
    "    m = gensim.models.keyedvectors.Word2VecKeyedVectors(vector_size=768)\n",
    "    m.add_vectors(list(mega_embeddings.keys()), list(mega_embeddings.values()))\n",
    "    m.save_word2vec_format(f\"{FOLDER_NAME}/gensim_prototype_embeddings_bert_{LAYER}.bin\")\n",
    "\n",
    "    with open(f\"{FOLDER_NAME}/prototype_embeddings_bert_{LAYER}.pkl\", \"wb\") as filino:\n",
    "        pickle.dump(mega_embeddings, filino)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a0d6bd-21f9-4d75-9254-98f0cbd51b79",
   "metadata": {},
   "source": [
    "### Non Contextualized Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d46aeb0-979e-417d-b566-48b9ded39e25",
   "metadata": {},
   "source": [
    "#### Method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "789fbd4a-e500-42a6-ba16-ab50360d1e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_to_embed = data[\"words\"].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "93eb34d2-0fca-4158-bede-164bff5ef97a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12c6e4a7926b4f72b8d85971fd51e5d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text tokenization:   0%|          | 0/2 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.62it/s]\n"
     ]
    }
   ],
   "source": [
    "df_slice_embedded = embeddings = model.embed(\n",
    "    words=words_to_embed,\n",
    "    layers_id=layers_of_interest,\n",
    "    target_texts=words_to_embed,\n",
    "    batch_size=8,\n",
    "    averaging=True,\n",
    "    return_static=True,\n",
    "    show_progress=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5db0fae-864a-4d6c-abe0-f739fbcfe891",
   "metadata": {},
   "source": [
    "#### Method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "47d118ba-0d68-4f86-aa53-02b8cd3550df",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in [-1] + layers_of_interest:\n",
    "    mega_embeddings = {}\n",
    "    for index,i in enumerate(words_to_embed):\n",
    "        \n",
    "        mega_embeddings[i] = df_slice_embedded[layer][index]\n",
    "    \n",
    "    \n",
    "    m = gensim.models.keyedvectors.Word2VecKeyedVectors(vector_size=768)\n",
    "    m.add_vectors(list(mega_embeddings.keys()), list(mega_embeddings.values()))\n",
    "    m.save_word2vec_format(f\"{FOLDER_NAME}/gensim_non_contextual_prototype_embeddings_bert_{LAYER}.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "56e18a6e-6b7b-4e88-81b0-9ec689a398d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target texts is None: extracting non contextualized embeddings.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5706bc7617a44aca8fec34a6e4dd9f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text tokenization:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                              | 0/1 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "embeddings = model.embed(\n",
    "        words=data[\"words\"].unique().tolist(),\n",
    "        layers_id=layers_of_interest,\n",
    "        batch_size=8,\n",
    "        averaging=True,\n",
    "        return_static=True,\n",
    "        show_progress=True,\n",
    "        add_special_tokens=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a51b77-e154-4708-b9aa-7f61a622a124",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in [-1] + layers_of_interest:\n",
    "    mega_embeddings = {}\n",
    "    for index,i in enumerate(words_to_embed):\n",
    "        \n",
    "        mega_embeddings[i] = embeddings[layer][index]\n",
    "    \n",
    "    \n",
    "    m = gensim.models.keyedvectors.Word2VecKeyedVectors(vector_size=768)\n",
    "    m.add_vectors(list(mega_embeddings.keys()), list(mega_embeddings.values()))\n",
    "    m.save_word2vec_format(f\"{FOLDER_NAME}/gensim_non_contextual_prototype_embeddings_bert_{LAYER}.bin\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newkernel",
   "language": "python",
   "name": "newkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}